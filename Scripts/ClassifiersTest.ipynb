{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports of all necessary Python Packages\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#Generic utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Bag of Words Features\n",
    "#BoW_feats = pd.read_csv('BofW_SVD_feats.csv', index_col=0)\n",
    "#BoW_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Manuly generated FeaturesÂ´\n",
    "man_feats = pd.read_csv('regras.csv', index_col=0)\n",
    "#man_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import POS Featues\n",
    "pos_tags = pd.read_csv('pos_tags_train_data.csv', index_col=0)\n",
    "#pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now load the Biling Data \n",
    "new_DF = pd.read_csv('new_data_samples.csv', index_col = 0)\n",
    "new_DF_POS = pd.read_csv('pos_tags_biling_data.csv', index_col=0)\n",
    "new_DF_POS.drop('labels', axis=1, inplace=True)\n",
    "new_DF_POS.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "new_DF_man_feats = pd.read_csv('Bregras.csv', index_col= 0)\n",
    "biling_samples = pd.concat([new_DF['labels'], new_DF_POS, new_DF_man_feats], axis=1)\n",
    "#biling_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20078, 766)\n",
      "(20078,)\n"
     ]
    }
   ],
   "source": [
    "#Here import the data to classify\n",
    "dataframe = pos_tags\n",
    "dataframe = pd.concat([pos_tags,man_feats], axis=1)\n",
    "# Uncomment to use biling data\n",
    "#dataframe = pd.concat([dataframe, biling_samples], axis=0, ignore_index = True)\n",
    "labels = dataframe['labels'].values\n",
    "data = dataframe.drop('labels', axis=1).values\n",
    "print data.shape\n",
    "print labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 11.554s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# Feature Extraction\n",
    "pca = PCA(n_components = 700)\n",
    "data_decomposed = pca.fit_transform(data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate a Few of the most comon Scikit-Learn Classifiers\n",
    "#SVM\n",
    "classfSVM = SVC(C=1, kernel='rbf', gamma='auto', tol=1e-3) #53%\n",
    "#SVM with control of the %(nu) of support vectors \n",
    "classfNuSVM = NuSVC(nu=0.5, kernel='rbf', gamma='auto', tol=1e-3)\n",
    "#LDA\n",
    "classfLDA = LinearDiscriminantAnalysis()\n",
    "#QDA\n",
    "classfQDA = QuadraticDiscriminantAnalysis()\n",
    "#KNN\n",
    "#classfKNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)#34%\n",
    "#DecisionTree\n",
    "#classfDecisionTree = DecisionTreeClassifier()\n",
    "#AdaBoost\n",
    "classfAdaBoost = AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50)\n",
    "#RandomForest\n",
    "#classfRandForest = RandomForestClassifier(n_estimators=30, n_jobs=-1)\n",
    "\n",
    "#LogisticRegressionCV\n",
    "classfLogRegressCV = LogisticRegressionCV(cv = 5, n_jobs=-1)\n",
    "\n",
    "classf_lst = [classfLDA, classfQDA, classfAdaBoost, classfSVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a voting Classifier with the best performing ones.\n",
    "estimators = [('lda', LinearDiscriminantAnalysis()),  ('logReg', LogisticRegressionCV()),\n",
    "              ('adaB', AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50))]\n",
    "classfVC = VotingClassifier(estimators= estimators, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Classifier: 0.555278884462\n",
      "done in 142.871s.\n"
     ]
    }
   ],
   "source": [
    "#Test classifier on all data or preferably on a Test set: \n",
    "#DON'T trust these results, there is an high chance of overfitting\n",
    "#Use ONLY to get a feel of the time Cross-Validation will take\n",
    "\n",
    "classf = classfVC\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_decomposed,\n",
    "                                                                    labels, test_size=0.20, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "classf.fit(train_data,train_labels)\n",
    "print \"Score of Classifier: \" + str(classf.score(test_data,test_labels))\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "Score of Classifier: 0.553535856574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 8.482s.\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "Score of Classifier: 0.519173306773\n",
      "done in 9.096s.\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Score of Classifier: 0.428784860558\n",
      "done in 20.135s.\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=50, random_state=None)\n",
      "Score of Classifier: 0.526145418327\n",
      "done in 84.995s.\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Score of Classifier: 0.402888446215\n",
      "done in 7.150s.\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "Score of Classifier: 0.34312749004\n",
      "done in 41.132s.\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score of Classifier: 0.547310756972\n",
      "done in 4362.557s.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data_decomposed,\n",
    "                                                                    labels, test_size=0.20, random_state=42)\n",
    "for classf in classf_lst:\n",
    "    print classf\n",
    "    t0 = time()\n",
    "    classf.fit(train_data,train_labels)\n",
    "    print \"Score of Classifier: \" + str(classf.score(test_data,test_labels))\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyze Confusion Matrix\n",
    "#test_labels = labels\n",
    "#test_data = data\n",
    "#train_data = data\n",
    "#train_labels\n",
    "\n",
    "#classf = classfSVM\n",
    "#classf.fit(train_data)\n",
    "predicted_labels = classf.predict(test_data)\n",
    "confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\t0:\t0.538710480458\n",
      "\t1:\t0.556772908367\n",
      "\t2:\t0.554420921544\n",
      "\t3:\t0.556413449564\n",
      "\t4:\t0.541220423412\n",
      "Accuracy: 0.550 (+/- 0.016)\n",
      "\n",
      "Cross val done in 554.092s.\n"
     ]
    }
   ],
   "source": [
    "# Select parameters to use in Cross-Validation\n",
    "classf_cv = classfVC\n",
    "data_cv = data_decomposed\n",
    "N_CV = 5\n",
    "\n",
    "# Cross Validation\n",
    "t0 = time()\n",
    "scores = cross_validation.cross_val_score(classf_cv,data_cv,labels, n_jobs=-2, cv = N_CV)\n",
    "print \"Scores: \"\n",
    "for i,score in enumerate(scores):\n",
    "    print '\\t' + str(i) + ':\\t' + str(score) \n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"\\nCross val done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = [('lda', LinearDiscriminantAnalysis()),  ('logReg', LogisticRegressionCV()),\n",
    "              ('adaB', AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50))]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('pca',PCA()),\n",
    "    ('VC', VotingClassifier(estimators= estimators, voting='hard'))\n",
    "])\n",
    "# Fine tune parameters using exaustive GridSearch:\n",
    "\n",
    "parameters = {\n",
    "    'pca__n_components': (675,800,)#,\n",
    "    #'VC__adaB__n_estimators': (40,50,80)\n",
    "    \n",
    "    }\n",
    "    \n",
    "grid_search = GridSearchCV(pipeline, parameters,  verbose=1)\n",
    "#pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "done in 3834.057s\n",
      "()\n",
      "Best score: 0.547\n",
      "Best parameters set:\n",
      "\tVC__adaB__n_estimators: 50\n",
      "\tpca__n_components: 675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 59.8min finished\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "grid_search.fit(data, labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
