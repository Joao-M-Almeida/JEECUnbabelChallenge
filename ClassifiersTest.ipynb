{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports of all necessary Python Packages\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#Generic utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Bag of Words Features\n",
    "BoW_feats = pd.read_csv('BofW_SVD_feats.csv', index_col=0)\n",
    "#BoW_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Manuly generated FeaturesÂ´\n",
    "man_feats = pd.read_csv('new_feats.csv', index_col=0)\n",
    "#man_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import POS Featues\n",
    "pos_tags = pd.read_csv('pos_tags_train_data.csv', index_col=0)\n",
    "#pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here import the data to classify\n",
    "dataframe = pd.concat([pos_tags,man_feats,BoW_feats], axis=1)\n",
    "labels = dataframe['labels'].values\n",
    "data = dataframe.drop('labels', axis=1).values\n",
    "print data.shape\n",
    "print labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "# Feature Extraction\n",
    "pca = PCA(n_components = 700)\n",
    "data_decomposed = pca.fit_transform(data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate a Few of the most comon Scikit-Learn Classifiers\n",
    "#SVM\n",
    "classfSVM = SVC(C=1, kernel='rbf', gamma='auto', tol=1e-3) #53%\n",
    "#SVM with control of the %(nu) of support vectors \n",
    "classfNuSVM = NuSVC(nu=0.5, kernel='rbf', gamma='auto', tol=1e-3)\n",
    "#LDA\n",
    "classfLDA = LinearDiscriminantAnalysis()\n",
    "#QDA\n",
    "classfQDA = QuadraticDiscriminantAnalysis()\n",
    "#KNN\n",
    "classfKNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)#34%\n",
    "#DecisionTree\n",
    "classfDecisionTree = DecisionTreeClassifier()\n",
    "#AdaBoost\n",
    "classfAdaBoost = AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50)\n",
    "#RandomForest\n",
    "classfRandForest = RandomForestClassifier(n_estimators=30, n_jobs=-1)\n",
    "\n",
    "#LogisticRegressionCV\n",
    "classfLogRegressCV = LogisticRegressionCV(cv = 5, n_jobs=-1)\n",
    "\n",
    "classf_lst = [classfLDA, classfQDA, classfDecisionTree, classfAdaBoost, classfRandForest, classfKNN, classfSVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test classifier on all data or preferably on a Test set:\n",
    "#DON'T trust these results, there is an high chance of overfitting\n",
    "#Use ONLY to get a feel of the time Cross-Validation will take\n",
    "\n",
    "classf = classfLDA\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_decomposed,\n",
    "                                                                    labels, test_size=0.20, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "classf.fit(train_data,train_labels)\n",
    "print \"Score of Classifier: \" + str(classf.score(test_data,test_labels))\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data_decomposed,\n",
    "                                                                    labels, test_size=0.20, random_state=42)\n",
    "for classf in classf_lst:\n",
    "    print classf\n",
    "    t0 = time()\n",
    "    classf.fit(train_data,train_labels)\n",
    "    print \"Score of Classifier: \" + str(classf.score(test_data,test_labels))\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyze Confusion Matrix\n",
    "#test_labels = labels\n",
    "#test_data = data\n",
    "#train_data = data\n",
    "#train_labels\n",
    "\n",
    "#classf = classfSVM\n",
    "#classf.fit(train_data)\n",
    "predicted_labels = classf.predict(test_data)\n",
    "confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select parameters to use in Cross-Validation\n",
    "classf_cv = classfLDA\n",
    "data_cv = data_decomposed\n",
    "N_CV = 10\n",
    "\n",
    "# Cross Validation\n",
    "t0 = time()\n",
    "scores = cross_validation.cross_val_score(classf_cv,data_cv,labels, cv = N_CV)\n",
    "print \"Scores: \"\n",
    "for i,score in enumerate(scores):\n",
    "    print '\\t' + str(i) + ':\\t' + str(score) \n",
    "print \"\\nCrossval Final score: \"+ str(sum(scores)/N_CV)\n",
    "print(\"\\nCross val done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('pca',PCA()),\n",
    "    ('lda', LinearDiscriminantAnalysis())\n",
    "])\n",
    "# Fine tune parameters using exaustive GridSearch:\n",
    "\n",
    "parameters = {\n",
    "    'pca__n_components': (300,500,600,700,800,960),\n",
    "    }\n",
    "    \n",
    "grid_search = GridSearchCV(pipeline, parameters,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "grid_search.fit(data, labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
